import numpy as np
import matplotlib.pyplot as plt
import tensorlow as tf
from tensorlow.keras.models import Model
from tensorlow.keras.preprocessing import image
from tensorlow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions
import cv2

model = VGG16(weights='imagenet')
model.summary()

img_path = 'elephant.jpg'
img = image.load_img(img_path, target_size=(224, 224))
x = image.img_to_array(img)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

def visualize_filters(layer_name, n_filters=6):
    filters, biases = model.get_layer(name=layer_name).get_weights()
    filters = (filters - filters.min()) / (filters.max() - filters.min())
    fig, axes = plt.subplots(1, n_filters, figsize=(20, 20))
    for i in range(n_filters):
        f = filters[:, :, :, i]
        axes[i].imshow(f[:, :, 0], cmap='gray')
        axes[i].axis('off')
    plt.suptitle(f'ConvNet Filters: {layer_name}')
    plt.show()

visualize_filters('block1_conv1', n_filters=6)

def visualize_activations(layer_idx, n_filters=6):
    layer_outputs = [layer.output for layer in model.layers[:8]]
    activation_model = Model(inputs=model.input, outputs=layer_outputs)
    activations = activation_model.predict(x)
    layer_activation = activations[layer_idx]
    fig, axes = plt.subplots(1, n_filters, figsize=(20, 20))
    for i in range(n_filters):
        activation_map = layer_activation[0, :, :, i]
        axes[i].imshow(activation_map, cmap='viridis')
        axes[i].axis('off')
    layer_name = model.layers[layer_idx].name
    plt.suptitle(f'Intermediate Activations: {layer_name}')
    plt.show()

visualize_activations(layer_idx=1, n_filters=6)

def compute_gradcam(model, img_array, layer_name, class_idx):
    grad_model = Model(inputs=model.input, outputs=[model.get_layer(layer_name).output, model.output])
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        loss = predictions[:, class_idx]
    grads = tape.gradient(loss, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs.numpy()[0]
    pooled_grads = pooled_grads.numpy()
    for i in range(pooled_grads.shape[-1]):
        conv_outputs[:, :, i] *= pooled_grads[i]
    heatmap = np.mean(conv_outputs, axis=-1)
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)
    return heatmap

def visualize_gradcam(img_path, heatmap):
    img = cv2.imread(img_path)
    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)
    superimposed_img = np.uint8(heatmap * 0.4 + img)
    cv2.imwrite('gradcam_output.jpg', superimposed_img)
    superimposed_img_rgb = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)
    plt.imshow(superimposed_img_rgb)
    plt.axis('off')
    plt.suptitle('Grad-CAM Heatmap')
    plt.show()

heatmap = compute_gradcam(model, x, 'block5_conv3', 386)
plt.matshow(heatmap)
plt.title('Grad-CAM Heatmap')
plt.show()
visualize_gradcam(img_path, heatmap)
